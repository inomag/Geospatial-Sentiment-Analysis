{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import csv\n",
    "from numpy import full\n",
    "import pandas as pd\n",
    "\n",
    "input1Csv = './datasets/Silchar.csv'\n",
    "output1Csv = './datasets/Silchar_caption.csv'\n",
    "\n",
    "input2Csv = './datasets/Guwahati.csv'\n",
    "output2Csv = './datasets/Guwahati_caption.csv'\n",
    "\n",
    "rowNum = 1\n",
    "\n",
    "with open (input1Csv, 'r', encoding = 'utf-8') as csvFile:\n",
    "    with open (output1Csv, 'w', encoding = 'utf-8', newline = '') as outFile:\n",
    "        data = csv.DictReader (csvFile)\n",
    "        fieldNames = ['Image Link', 'Redirected Link']\n",
    "        writer = csv.DictWriter (outFile, fieldnames = fieldNames)\n",
    "        writer.writerow ({'Image Link': 'Image Link', 'Redirected Link': 'Redirected Link'})\n",
    "\n",
    "        for row in data:\n",
    "            fullText = row['Text']+\" \"+row['Full Text']\n",
    "            fullText = \" \".join(fullText.split())\n",
    "\n",
    "            urls = re.findall(r'(https?://[^\\s]+)', fullText)\n",
    "            links = ''\n",
    "            redirects = ''\n",
    "            for url in urls:\n",
    "                try:\n",
    "                    r = requests.get(url)\n",
    "                    links += url+' | '\n",
    "                    redirects += r.url + ' | '\n",
    "                except Exception as e:\n",
    "                    print(\"Url Error\")\n",
    "            writer.writerow ({'Image Link': links, 'Redirected Link': redirects})\n",
    "            print ('Row', rowNum, 'Done')\n",
    "            rowNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowNum = 1\n",
    "\n",
    "with open (input2Csv, 'r', encoding = 'utf-8') as csvFile:\n",
    "    with open (output2Csv, 'w', encoding = 'utf-8', newline = '') as outFile:\n",
    "        data = csv.DictReader (csvFile)\n",
    "        fieldNames = ['Image Link', 'Redirected Link']\n",
    "        writer = csv.DictWriter (outFile, fieldnames = fieldNames)\n",
    "        writer.writerow ({'Image Link': 'Image Link', 'Redirected Link': 'Redirected Link'})\n",
    "\n",
    "        for row in data:\n",
    "            fullText = row['Text']+\" \"+row['Full Text']\n",
    "            fullText = \" \".join(fullText.split())\n",
    "\n",
    "            urls = re.findall(r'(https?://[^\\s]+)', fullText)\n",
    "            links = ''\n",
    "            redirects = ''\n",
    "            for url in urls:\n",
    "                try:\n",
    "                    r = requests.get(url)\n",
    "                    links += url+' | '\n",
    "                    redirects += r.url + ' | '\n",
    "                except Exception as e:\n",
    "                    print(\"Url Error\")\n",
    "            writer.writerow ({'Image Link': links, 'Redirected Link': redirects})\n",
    "            print ('Row', rowNum, 'Done')\n",
    "            rowNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/Silchar_caption.csv\")\n",
    "finalLinks = []\n",
    "for i in range(len(df)):\n",
    "    links = df.loc[i,'Redirected Link']\n",
    "    if links!=links:\n",
    "        links = \" \"\n",
    "    links = links.split(' | ')\n",
    "    tmp = ''\n",
    "    for link in links:\n",
    "        code = re.findall(\"/p/([^/?#&]+)/\", link)\n",
    "        if code:\n",
    "            tmp += \"https://www.instagram.com/p/\"+code[0]+\"/ | \"\n",
    "    finalLinks.append(tmp)\n",
    "df['Final Links'] = finalLinks\n",
    "df.to_csv(\"./datasets/Silchar_caption.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/Guwahati_caption.csv\")\n",
    "finalLinks = []\n",
    "for i in range(len(df)):\n",
    "    links = df.loc[i,'Redirected Link']\n",
    "    if links!=links:\n",
    "        links = \" \"\n",
    "    links = links.split(' | ')\n",
    "    tmp = ''\n",
    "    for link in links:\n",
    "        code = re.findall(\"/p/([^/?#&]+)/\", link)\n",
    "        if code:\n",
    "            tmp += \"https://www.instagram.com/p/\"+code[0]+\"/ | \"\n",
    "    finalLinks.append(tmp)\n",
    "df['Final Links'] = finalLinks\n",
    "df.to_csv(\"./datasets/Guwahati_caption.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "234add224a49453f14ca85c5a2b4bc3db3f703c851e7b7dcb1c661491c6686f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
