{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from translate import Translator\n",
    "import emoji\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/Guwahati.csv')\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "demojized = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    finalText = ''\n",
    "    text = df.loc[i,'Text']\n",
    "    fulltext = df.loc[i,'Full Text']\n",
    "\n",
    "    if text==text:\n",
    "        finalText += text + \" \"\n",
    "    if fulltext==fulltext:\n",
    "        finalText += fulltext + \" \"\n",
    "    finalText = re.sub(r\"http\\S+\", \"\",  finalText)\n",
    "    finalText = emoji.demojize(finalText,delimiters=(\"\", \" \")).replace('_',' ').replace('-',' ')\n",
    "    demojized.append(finalText)\n",
    "\n",
    "output['Demojized'] = demojized\n",
    "# output.to_csv(\"./final datasets/Guwahati_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/Silchar.csv')\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "demojized = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    finalText = ''\n",
    "    text = df.loc[i,'Text']\n",
    "    fulltext = df.loc[i,'Full Text']\n",
    "\n",
    "    if text==text:\n",
    "        finalText += text + \" \"\n",
    "    if fulltext==fulltext:\n",
    "        finalText += fulltext + \" \"\n",
    "    finalText = re.sub(r\"http\\S+\", \"\",  finalText)\n",
    "    finalText = emoji.demojize(finalText,delimiters=(\"\", \" \")).replace('_',' ').replace('-',' ')\n",
    "    demojized.append(finalText)\n",
    "\n",
    "output['Demojized'] = demojized\n",
    "# output.to_csv(\"./final datasets/Silchar_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv('./final datasets/Silchar_Data.csv')\n",
    "\n",
    "df = pd.read_csv('./datasets/Silchar_caption.csv')\n",
    "\n",
    "captions = []\n",
    "for i in range(len(df)):\n",
    "    caption = ''\n",
    "    links = df.loc[i,'Final Links']\n",
    "    if links!=links:\n",
    "        captions.append(caption)\n",
    "        continue\n",
    "    links = links.split(' | ')\n",
    "    for link in links:\n",
    "        try:\n",
    "            instaUrl = \"http://api.instagram.com/oembed?url=\"+link\n",
    "            r = requests.get(instaUrl)\n",
    "            caption+=\" \"+r.json()['title']\n",
    "        except Exception as e:\n",
    "            print(\"Url Error\")\n",
    "    caption = re.sub('[^a-zA-Z0-9 \\.]', ' ', caption)\n",
    "    caption = emoji.demojize(caption,delimiters=(\"\", \" \")).replace('_',' ').replace('-',' ')\n",
    "    print(caption)\n",
    "    captions.append(caption)\n",
    "\n",
    "out['Captions'] = captions\n",
    "# out.to_csv(\"./final datasets/Silchar_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv('./final datasets/Guwahati_Data.csv')\n",
    "\n",
    "df = pd.read_csv('./datasets/Guwahati_caption.csv')\n",
    "\n",
    "captions = []\n",
    "for i in range(len(df)):\n",
    "    caption = ''\n",
    "    links = df.loc[i,'Final Links']\n",
    "    if links!=links:\n",
    "        captions.append(caption)\n",
    "        continue\n",
    "    links = links.split(' | ')\n",
    "    for link in links:\n",
    "        try:\n",
    "            instaUrl = \"http://api.instagram.com/oembed?url=\"+link\n",
    "            r = requests.get(instaUrl)\n",
    "            caption+=\" \"+r.json()['title']\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    caption = re.sub('[^a-zA-Z0-9 \\.]', ' ', caption)\n",
    "    caption = emoji.demojize(caption,delimiters=(\"\", \" \")).replace('_',' ').replace('-',' ')\n",
    "    captions.append(caption)\n",
    "\n",
    "out['Captions'] = captions\n",
    "# out.to_csv(\"./final datasets/Guwahati_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Created (UTC)', 'Latitude', 'Longitude', 'Text', 'Full Text',\n",
      "       'User Name', 'User Mentions', 'Hashtags', 'Language', 'Retweet count',\n",
      "       'Country', 'Place', 'Image'],\n",
      "      dtype='object')\n",
      "Index(['Demojized', 'Captions', 'Latitude', 'Longitude', 'Retweet Count',\n",
      "       'Created (UTC)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "input = pd.read_csv('./datasets/Guwahati.csv')\n",
    "out = pd.read_csv('./final datasets/Guwahati_Data.csv')\n",
    "\n",
    "# out['Latitude'] = input['Latitude']\n",
    "# out['Longitude'] = input['Longitude']\n",
    "# out['Retweet Count'] = input['Retweet count']\n",
    "# out['Created (UTC)'] = input['Created (UTC)']\n",
    "\n",
    "# out.to_csv('./final datasets/Guwahati_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Created (UTC)', 'Latitude', 'Longitude', 'Text', 'Full Text',\n",
      "       'User Name', 'User Mentions', 'Hashtags', 'Language', 'Retweet count',\n",
      "       'Country', 'Place', 'Image'],\n",
      "      dtype='object')\n",
      "Index(['Demojized', 'Captions', 'Latitude', 'Longitude', 'Retweet Count',\n",
      "       'Created (UTC)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "input = pd.read_csv('./datasets/Silchar.csv')\n",
    "out = pd.read_csv('./final datasets/Silchar_Data.csv')\n",
    "\n",
    "print(input.columns)\n",
    "print(out.columns)\n",
    "\n",
    "# out['Latitude'] = input['Latitude']\n",
    "# out['Longitude'] = input['Longitude']\n",
    "# out['Retweet Count'] = input['Retweet count']\n",
    "# out['Created (UTC)'] = input['Created (UTC)']\n",
    "\n",
    "# out.to_csv('./final datasets/Silchar_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "234add224a49453f14ca85c5a2b4bc3db3f703c851e7b7dcb1c661491c6686f6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
